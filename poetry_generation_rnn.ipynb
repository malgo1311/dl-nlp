{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Embedding, Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 1436)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lines = []\n",
    "target_lines = []\n",
    "\n",
    "for line in open('data/robert_frost.txt'):\n",
    "    temp_line = line.strip()\n",
    "    \n",
    "    if not temp_line:\n",
    "        continue\n",
    "    \n",
    "    out_line = temp_line + ' <eos>'\n",
    "    inp_line = '<sos> ' + temp_line\n",
    "    \n",
    "    input_lines.append(inp_line)\n",
    "    target_lines.append(out_line)\n",
    "    \n",
    "len(input_lines), len(target_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2872"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = input_lines + target_lines\n",
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_ = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "tokenizer_.fit_on_texts(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3056"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Total number of unique words\n",
    "word2ind = tokenizer_.word_index\n",
    "len(word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = tokenizer_.texts_to_sequences(input_lines)\n",
    "target_sequences = tokenizer_.texts_to_sequences(target_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Two roads diverged in a yellow wood, <eos>',\n",
       " [104, 537, 538, 9, 7, 539, 540, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target_lines[0], target_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_WORDS = min(len(word2ind) + 1, MAX_VOCAB_SIZE)\n",
    "NUM_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## getting max len\n",
    "MAX_SEQUENCE_LEN = max([len(s) for s in input_sequences])\n",
    "MAX_SEQUENCE_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_input_sequences = pad_sequences(input_sequences, maxlen=MAX_SEQUENCE_LEN, padding='post')\n",
    "padded_target_sequences = pad_sequences(target_sequences, maxlen=MAX_SEQUENCE_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104, 537, 538,   9,   7, 539, 540,   2,   0,   0,   0,   0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_target_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Need to one-hot the targets because cannot use sparse-categorical-crossentropy for list of outputs\n",
    "one_hot_targets = np.zeros((len(padded_target_sequences), MAX_SEQUENCE_LEN, NUM_WORDS))\n",
    "\n",
    "for i, seq in enumerate(padded_target_sequences):\n",
    "    \n",
    "    for j, word_ind in enumerate(seq):\n",
    "        \n",
    "        one_hot_targets[i, j, word_ind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 12, 3000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "word2vec = {}\n",
    "for line in open('glove.6B/glove.6B.{0}d.txt'.format(EMBEDDING_DIM)):\n",
    "    temp = line.strip().split(' ')\n",
    "    word = temp[0]\n",
    "    arr = np.asarray(temp[1:], dtype='float16')\n",
    "    word2vec[word] = arr\n",
    "\n",
    "print(len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec['is']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 50)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((NUM_WORDS, EMBEDDING_DIM))\n",
    "for k, i in word2ind.items():\n",
    "\n",
    "    if i < MAX_VOCAB_SIZE:\n",
    "        embedding_vector = word2vec.get(k)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_2 = embedding_matrix.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aishwaryamalgonde/Aishwarya/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:71: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## create the embedding_layer\n",
    "embedding_layer = Embedding(input_dim=NUM_WORDS, output_dim=EMBEDDING_DIM, weights=[embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aishwaryamalgonde/Aishwarya/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:514: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(MAX_SEQUENCE_LEN, ))\n",
    "initial_h = Input(shape=(LATENT_DIM, ))\n",
    "initial_c = Input(shape=(LATENT_DIM, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aishwaryamalgonde/Aishwarya/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4076: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aishwaryamalgonde/Aishwarya/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:171: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aishwaryamalgonde/Aishwarya/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:178: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aishwaryamalgonde/Aishwarya/venv/lib/python3.7/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = embedding_layer(input_)\n",
    "\n",
    "lstm1 = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "x, _, _ = lstm1(x, initial_state = [initial_h, initial_c])\n",
    "\n",
    "dense = Dense(NUM_WORDS, activation='softmax')\n",
    "output = dense(x)\n",
    "\n",
    "model = Model([input_,initial_h,initial_c], output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1148 samples, validate on 288 samples\n",
      "Epoch 1/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.5445 - acc: 0.5033 - val_loss: 5.6430 - val_acc: 0.3753\n",
      "Epoch 2/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.4920 - acc: 0.5068 - val_loss: 5.6644 - val_acc: 0.3750\n",
      "Epoch 3/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.4593 - acc: 0.5108 - val_loss: 5.7069 - val_acc: 0.3730\n",
      "Epoch 4/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.4224 - acc: 0.5152 - val_loss: 5.7581 - val_acc: 0.3736\n",
      "Epoch 5/20\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.3922 - acc: 0.5200 - val_loss: 5.7806 - val_acc: 0.3727\n",
      "Epoch 6/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.3632 - acc: 0.5210 - val_loss: 5.8455 - val_acc: 0.3741\n",
      "Epoch 7/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.3446 - acc: 0.5232 - val_loss: 5.8704 - val_acc: 0.3678\n",
      "Epoch 8/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.3206 - acc: 0.5264 - val_loss: 5.8824 - val_acc: 0.3715\n",
      "Epoch 9/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.2975 - acc: 0.5304 - val_loss: 5.9347 - val_acc: 0.3689\n",
      "Epoch 10/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.2768 - acc: 0.5338 - val_loss: 5.9521 - val_acc: 0.3718\n",
      "Epoch 11/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.2629 - acc: 0.5343 - val_loss: 5.9857 - val_acc: 0.3709\n",
      "Epoch 12/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.2469 - acc: 0.5358 - val_loss: 6.0212 - val_acc: 0.3727\n",
      "Epoch 13/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.2267 - acc: 0.5387 - val_loss: 6.0430 - val_acc: 0.3724\n",
      "Epoch 14/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.2096 - acc: 0.5436 - val_loss: 6.0737 - val_acc: 0.3718\n",
      "Epoch 15/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.2032 - acc: 0.5401 - val_loss: 6.0969 - val_acc: 0.3707\n",
      "Epoch 16/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.1924 - acc: 0.5420 - val_loss: 6.0945 - val_acc: 0.3695\n",
      "Epoch 17/20\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 2.1862 - acc: 0.5448 - val_loss: 6.1440 - val_acc: 0.3718\n",
      "Epoch 18/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.1762 - acc: 0.5454 - val_loss: 6.1247 - val_acc: 0.3669\n",
      "Epoch 19/20\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 2.1619 - acc: 0.5476 - val_loss: 6.1748 - val_acc: 0.3675\n",
      "Epoch 20/20\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.1538 - acc: 0.5467 - val_loss: 6.1893 - val_acc: 0.3672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14c0632d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros((len(padded_input_sequences), LATENT_DIM))\n",
    "\n",
    "# model.fit(padded_input_sequences,\n",
    "model.fit([padded_input_sequences, z, z],\n",
    "          one_hot_targets,\n",
    "          epochs=20,\n",
    "          batch_size=5,\n",
    "          validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2 = Input(shape=(1, ))\n",
    "x = embedding_layer(input_2)\n",
    "x, h, c = lstm1(x, initial_state = [initial_h, initial_c])\n",
    "output2 = dense(x)\n",
    "\n",
    "sampling_model = Model([input_2,initial_h,initial_c], [output2, h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3056"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2word = {v:k for k, v in word2ind.items()}\n",
    "len(ind2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem():\n",
    "    \n",
    "    sos = word2ind['<sos>']\n",
    "    input_p = np.array([[sos]])\n",
    "    \n",
    "    h = np.zeros((1, LATENT_DIM))\n",
    "    c = np.zeros((1, LATENT_DIM))\n",
    "    \n",
    "    eos = word2ind['<eos>']\n",
    "    \n",
    "    generated_output = []\n",
    "    \n",
    "    for _ in range(MAX_SEQUENCE_LEN):\n",
    "        p, h, c = sampling_model.predict([input_p, h, c])\n",
    "        \n",
    "        # probabilties\n",
    "        probs = p[0,0]\n",
    "        \n",
    "        # if probabilty of <sos> is high then it prints a warning\n",
    "        if np.argmax(probs) == sos:\n",
    "            print('wtf')\n",
    "        \n",
    "        # setting probabilty of  <sos> to 0\n",
    "        probs[0] = 0\n",
    "        probs /= sum(probs)\n",
    "        \n",
    "        # randomly choosing index based on probability distribution\n",
    "        # so that we get different output each time\n",
    "        index = np.random.choice(len(probs), p = probs)\n",
    "        \n",
    "        if index == eos:\n",
    "            break\n",
    "\n",
    "        generated_output.append(ind2word.get(index, '<WTF> %s'% index))\n",
    "        input_p[0][0] = index\n",
    "    \n",
    "    return ' '.join(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i stole the sockets of spray;\n"
     ]
    }
   ],
   "source": [
    "print(generate_poem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
